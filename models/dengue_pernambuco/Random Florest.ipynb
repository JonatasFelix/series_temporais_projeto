{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from pathlib import Path"
   ],
   "id": "a2acf1ed2fb55bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_lags(df, lags_list, target_col='valor', window_size=4):\n",
    "    \"\"\"\n",
    "    Cria defasagens (lags), features de janela móvel, e features de tempo/sazonalidade\n",
    "    (Ano, Mês e componentes Seno/Cosseno) para a série temporal.\n",
    "\n",
    "    df (DataFrame): O DataFrame original com a série temporal (índice datetime).\n",
    "    lags_list (list): Lista de defasagens a serem criadas (ex: [1, 52]).\n",
    "    target_col (str): Nome da coluna alvo (y_t).\n",
    "    window_size (int): Tamanho da janela para as estatísticas móveis.\n",
    "    \"\"\"\n",
    "    # DataFrame auxiliar para armazenar as features.\n",
    "    df_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # 1. Variável Alvo (y_t): O valor da série no momento t.\n",
    "    df_features['y'] = df[target_col].copy()\n",
    "\n",
    "    # --- NOVO BLOCO DE FEATURE ENGINEERING: FEATURES DE TEMPO E SAZONALIDADE ---\n",
    "\n",
    "    # Extrai features simples de calendário\n",
    "    df_features['time_index'] = np.arange(len(df_features)) + 1\n",
    "    # Adicione esta linha junto com a criação do 'time_index'\n",
    "    df_features['time_index_sq'] = df_features['time_index'] ** 2\n",
    "    df_features['ano'] = df.index.year\n",
    "    df_features['mes'] = df.index.month\n",
    "    df_features['semana_do_ano'] = df.index.isocalendar().week.astype(int)\n",
    "\n",
    "    # Cria features de sazonalidade cíclica (Seno/Cosseno)\n",
    "    # Máximo de semanas em um ano = 52\n",
    "    period = 52.0\n",
    "    df_features['sin_semana'] = np.sin(2 * np.pi * df_features['semana_do_ano'] / period)\n",
    "    df_features['cos_semana'] = np.cos(2 * np.pi * df_features['semana_do_ano'] / period)\n",
    "\n",
    "    # Remove colunas intermediárias (semana_do_ano não é mais necessária)\n",
    "    df_features.drop('semana_do_ano', axis=1, inplace=True)\n",
    "\n",
    "    # --- FIM DO NOVO BLOCO ---\n",
    "\n",
    "    # 2. Features de Defasagem (X): Valores da série em momentos passados (y_{t-k}).\n",
    "    for lag in lags_list:\n",
    "        df_features[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "\n",
    "    # 3. Features de Janela Móvel (Rolling Windows)\n",
    "    # Usamos shift(1) para garantir que a janela móvel só use dados do passado.\n",
    "    rolling_window = df[target_col].shift(1).rolling(window=window_size)\n",
    "\n",
    "    df_features[f'rolling_mean_{window_size}'] = rolling_window.mean()\n",
    "    df_features[f'rolling_std_{window_size}'] = rolling_window.std()\n",
    "    df_features[f'rolling_max_{window_size}'] = rolling_window.max()\n",
    "    df_features[f'rolling_min_{window_size}'] = rolling_window.min()\n",
    "\n",
    "    # Remove as linhas iniciais que contêm valores NaN (devido aos lags e janelas).\n",
    "    df_features.dropna(inplace=True)\n",
    "\n",
    "    # X é a matriz de features, Y é a variável alvo.\n",
    "    X = df_features.drop('y', axis=1)\n",
    "    Y = df_features['y']\n",
    "\n",
    "    return X, Y\n"
   ],
   "id": "50078fe62f04c51c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CAMINHO_RAIZ = Path(os.getcwd()).resolve().parent.parent\n",
    "OUTPUT = CAMINHO_RAIZ / 'out' / 'dengue_pernambuco'\n",
    "os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "dengue_pe = pd.read_excel(CAMINHO_RAIZ / 'data' / 'dengue_pernambuco.xlsx')\n",
    "print('Dimensões do dataset:', dengue_pe.shape)\n",
    "print('Colunas:', dengue_pe.columns.tolist())\n",
    "display(dengue_pe.head(8))"
   ],
   "id": "e5d47a7e6250c7f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dengue_pe['semana'] = pd.to_datetime(dengue_pe['semana'])\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(dengue_pe['semana'], dengue_pe['valor'])\n",
    "plt.title('Série temporal de casos')\n",
    "plt.xlabel('semana')\n",
    "plt.ylabel('valor')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(dengue_pe['valor'], bins=60, kde=False)\n",
    "plt.title('Distribuição de valores')\n",
    "plt.show()\n",
    "dengue_pe.set_index('semana', inplace=True)\n",
    "dengue_pe.sort_index(inplace=True)"
   ],
   "id": "91885ef01f45a077"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_obs = len(dengue_pe)\n",
    "p_train = 0.50\n",
    "p_val = 0.25\n",
    "n_train = int(n_obs * p_train)\n",
    "n_val = int(n_obs * p_val)\n",
    "n_test = n_obs - n_train - n_val\n",
    "\n",
    "dengue_train = dengue_pe.iloc[:n_train]\n",
    "dengue_val = dengue_pe.iloc[n_train: n_train + n_val]\n",
    "dengue_test = dengue_pe.iloc[n_train + n_val:]"
   ],
   "id": "d879432a91872bc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "LAG_FEATURES = [1, 2, 3, 4, 12, 52]\n",
    "\n",
    "# 2. Aplicamos a mesma função de antes, mas agora passamos o 'window_size'.\n",
    "# A função irá criar automaticamente as features de média, desvio padrão, etc.\n",
    "X_full, Y_full = create_lags(dengue_pe, LAG_FEATURES, window_size=4)\n",
    "\n",
    "\n",
    "# Exibimos as primeiras linhas para verificar as NOVAS features.\n",
    "print(\"Estrutura do Conjunto de Features e Alvo (X e Y):\")\n",
    "print(\"Novas colunas em X:\", X_full.columns.tolist())\n",
    "print(\"\\n\")\n",
    "print(X_full.head())"
   ],
   "id": "ea56f44ace3c21f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Definição das colunas que recebem np.log1p\n",
    "COLS_TO_TRANSFORM = [col for col in X_full.columns if 'lag_' in col or 'rolling_' in col]\n",
    "\n",
    "train_val_end_date = dengue_val.index.max()\n",
    "train_end_date = dengue_train.index.max()\n",
    "\n",
    "# --- Separação com Transformação Seletiva ---\n",
    "\n",
    "# TREINO\n",
    "X_train = X_full.loc[:train_end_date].copy()\n",
    "X_train[COLS_TO_TRANSFORM] = np.log1p(X_train[COLS_TO_TRANSFORM])\n",
    "Y_train = np.log1p(Y_full.loc[:train_end_date])\n",
    "\n",
    "# VALIDAÇÃO\n",
    "X_val = X_full.loc[train_end_date:train_val_end_date].iloc[1:].copy()\n",
    "X_val[COLS_TO_TRANSFORM] = np.log1p(X_val[COLS_TO_TRANSFORM])\n",
    "Y_val = np.log1p(Y_full.loc[train_end_date:train_val_end_date].iloc[1:])\n",
    "\n",
    "# TESTE\n",
    "X_test = X_full.loc[train_val_end_date:].iloc[1:].copy()\n",
    "X_test[COLS_TO_TRANSFORM] = np.log1p(X_test[COLS_TO_TRANSFORM])\n",
    "Y_test = np.log1p(Y_full.loc[train_val_end_date:].iloc[1:])\n",
    "\n",
    "# --- Limpeza Final (Crucial para NaN/Inf) ---\n",
    "\n",
    "# 1. Recriação do conjunto Treino/Validação (a ser otimizado)\n",
    "X_train_val = pd.concat([X_train, X_val])\n",
    "Y_train_val = pd.concat([Y_train, Y_val])\n",
    "\n",
    "# 2. Limpeza Agressiva\n",
    "X_train_val.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 3. Imputação com a média de X_train_val\n",
    "train_val_mean = X_train_val.mean()\n",
    "X_train_val.fillna(train_val_mean, inplace=True)\n",
    "X_test.fillna(train_val_mean, inplace=True)\n",
    "\n",
    "# 4. Conversão para float64 (Solução para o erro persistente de dtype)\n",
    "X_train_val = X_train_val.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "# Verificação:\n",
    "print(f\"time_index após separação (deve ser linear): {X_train_val['time_index'].head()}\")"
   ],
   "id": "a32e02f5a6ecee9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def reverse_log_mape_scorer(Y_true, Y_pred):\n",
    "    \"\"\"Reverte a transformação logarítmica (np.expm1) para calcular o MAPE em casos reais.\"\"\"\n",
    "    # A métrica usa np.expm1() para converter os valores logarítmicos de volta à escala original (casos de dengue).\n",
    "    return mean_absolute_percentage_error(np.expm1(Y_true), np.expm1(Y_pred))\n",
    "\n",
    "# Criamos o scorer para ser usado no RandomizedSearchCV.\n",
    "# greater_is_better=False indica que o MAPE deve ser MINIMIZADO.\n",
    "mape_negativo = make_scorer(reverse_log_mape_scorer, greater_is_better=False)\n",
    "\n",
    "# --- 2. EXECUÇÃO DO RANDOMIZED SEARCH (AJUSTADA) ---\n",
    "\n",
    "# Define o espaço de busca para o Random Forest. (MANTIDO O SEU)\n",
    "param_dist = {\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_leaf': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# TimeSeriesSplit (MANTIDO O SEU)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# RandomizedSearchCV: Realiza a busca aleatória.\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42, n_jobs=-1), # Adicionado n_jobs=-1 para paralelismo\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30, # Testaremos 20 combinações\n",
    "    scoring=mape_negativo, # CORREÇÃO: Usando o scorer com reversão logarítmica\n",
    "    cv=tscv,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# O método fit() executa a busca no conjunto Treinamento + Validação (X_train_val).\n",
    "random_search.fit(X_train_val, Y_train_val)\n",
    "\n",
    "# best_params_ armazena os hiperparâmetros que obtiveram o melhor score (menor MAPE) na validação cruzada.\n",
    "best_params_ap = random_search.best_params_\n",
    "best_score_ap = -random_search.best_score_ # Reverte o score para o MAPE positivo.\n",
    "\n",
    "print(\"\\n--- Modelo AP (Random Forest) Selecionado ---\")\n",
    "print(f\"Melhores Parâmetros (Random Search): {best_params_ap}\")\n",
    "print(f\"Melhor MAPE na Validação Cruzada: {best_score_ap:.2%}\")"
   ],
   "id": "6f122b9b9768ac52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- TREINAMENTO FINAL (CÉLULA COM O ERRO) ---\n",
    "\n",
    "# Instancia o Random Forest com os melhores parâmetros encontrados.\n",
    "# (Assumindo que best_params_ap já foi definido pelo RandomizedSearchCV)\n",
    "rf_ap_model = RandomForestRegressor(**best_params_ap, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Treinamento final no conjunto X_train_val (agora totalmente float64).\n",
    "rf_ap_model.fit(X_train_val, Y_train_val)\n",
    "\n",
    "# Previsões: ESTE BLOCO DEVE RODAR SEM ERRO AGORA\n",
    "y_pred_train_ap = rf_ap_model.predict(X_train)\n",
    "y_pred_val_ap = rf_ap_model.predict(X_val)\n",
    "y_pred_test_ap = rf_ap_model.predict(X_test)"
   ],
   "id": "b45259505909df2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Linha real contínua\n",
    "plt.plot(pd.concat([Y_train_val, Y_val, Y_test]),\n",
    "         label=\"Real\", color=\"black\", linewidth=2)\n",
    "\n",
    "# Previsões destacadas por fase\n",
    "plt.plot(pd.Series(y_pred_train_ap, index=Y_train_val.index[-len(y_pred_train_ap):]),\n",
    "         label=\"Previsto (Treino)\", color=\"blue\", linestyle=\"--\")\n",
    "\n",
    "plt.plot(pd.Series(y_pred_val_ap, index=Y_val.index),\n",
    "         label=\"Previsto (Validação)\", color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "plt.plot(pd.Series(y_pred_test_ap, index=Y_test.index),\n",
    "         label=\"Previsto (Teste)\", color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.title(\"Valores Reais vs Previstos - Treino, Validação e Teste\")\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(OUTPUT / 'Random Florest - Valores Reais vs Previstos - Treino, Validação e Teste.png')\n",
    "plt.show()\n"
   ],
   "id": "421b301e89499a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# O modelo já está treinado e otimizado (rf_ap_model)\n",
    "# Note: X_train_val é o conjunto com as colunas de features\n",
    "feature_importances = pd.Series(\n",
    "    rf_ap_model.feature_importances_,\n",
    "    index=X_train_val.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# Top 5 Features:\n",
    "print(\"\\nAs 5 features mais importantes são:\")\n",
    "print(feature_importances.head(5))\n",
    "\n",
    "# Plot da Importância das Features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importances.values, y=feature_importances.index, color='skyblue')\n",
    "plt.title('Importância das Features (Random Forest)')\n",
    "plt.xlabel('Score de Importância')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9435eb4b0e051874"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Métrica de Erro: Cálculo do EQM e MAPE\n",
    "def evaluate_metrics(y_true, y_pred, name):\n",
    "    \"\"\"Calcula e retorna EQM e MAPE para um conjunto específico.\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return {'Conjunto': name, 'EQM': mse, 'MAPE': mape}\n",
    "\n",
    "results_ap = [\n",
    "    evaluate_metrics(Y_train, y_pred_train_ap, 'Treinamento (AP)'),\n",
    "    evaluate_metrics(Y_val, y_pred_val_ap, 'Validação (AP)'),\n",
    "    evaluate_metrics(Y_test, y_pred_test_ap, 'Teste (AP)')\n",
    "]\n",
    "df = pd.DataFrame(results_ap)\n",
    "for val in results_ap:\n",
    "    print(val)\n",
    "\n",
    "# Gráfico de barras lado a lado\n",
    "fig, ax1 = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# EQM\n",
    "ax1[0].bar(df['Conjunto'], df['EQM'], color=['blue','orange','red'])\n",
    "ax1[0].set_title(\"EQM (Erro Quadrático Médio)\")\n",
    "ax1[0].set_ylabel(\"Valor\")\n",
    "\n",
    "# MAPE\n",
    "ax1[1].bar(df['Conjunto'], df['MAPE'], color=['blue','orange','red'])\n",
    "ax1[1].set_title(\"MAPE (Erro Percentual Absoluto Médio)\")\n",
    "ax1[1].set_ylabel(\"Valor\")\n",
    "\n",
    "plt.suptitle(\"Comparação de Métricas por Conjunto\")\n",
    "plt.savefig(OUTPUT / 'Random Florest - Comparação de Métricas por Conjunto.png')\n",
    "plt.show()\n"
   ],
   "id": "14f0d910f9e844f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "residuos = Y_test - y_pred_test_ap\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(residuos, bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Distribuição dos Erros\")\n",
    "plt.xlabel(\"Erro\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.savefig(OUTPUT / 'Random Florest - Distribuição dos Erros.png')\n",
    "plt.show()"
   ],
   "id": "3c42c9ad037e38b0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
