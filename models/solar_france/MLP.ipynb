{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f02ade4",
   "metadata": {},
   "source": [
    "# MLP (Multi-Layer Perceptron) - Produção Solar França\n",
    "\n",
    "## Objetivo\n",
    "Modelar e prever a produção de energia solar na França usando redes neurais MLP\n",
    "\n",
    "## Dataset\n",
    "- **Arquivo**: solar_france.xlsx\n",
    "- **Variável Target**: Production (produção solar)\n",
    "- **Frequência**: Dados horários\n",
    "- **Abordagem**: Transformar série temporal em problema supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os, json, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize']=(12,6)\n",
    "sns.set_palette('husl')\n",
    "\n",
    "output_dir='../../out/solar_france/MLP'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ecfd9",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acbf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "data_path = '../../data/solar_france.xlsx'\n",
    "df = pd.read_excel(data_path)\n",
    "df['Date and Hour'] = pd.to_datetime(df['Date and Hour'])\n",
    "df = df.set_index('Date and Hour').sort_index().dropna()\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "print('Período:', df.index.min(), '->', df.index.max())\n",
    "print('\\nEstatísticas:')\n",
    "print(df['Production'].describe())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33eebb",
   "metadata": {},
   "source": [
    "## 2. Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a16bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data, n_lags=24):\n",
    "    \"\"\"\n",
    "    Criar features temporais para MLP\n",
    "    \"\"\"\n",
    "    X = pd.DataFrame(index=data.index)\n",
    "    y = data['Production']\n",
    "    \n",
    "    # Features de lag\n",
    "    for i in range(1, n_lags+1):\n",
    "        X[f'lag_{i}'] = y.shift(i)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    for w in [3, 6, 12, 24, 48]:\n",
    "        X[f'roll_mean_{w}'] = y.rolling(w).mean()\n",
    "        X[f'roll_std_{w}'] = y.rolling(w).std()\n",
    "        X[f'roll_max_{w}'] = y.rolling(w).max()\n",
    "        X[f'roll_min_{w}'] = y.rolling(w).min()\n",
    "    \n",
    "    # Features temporais\n",
    "    X['hour'] = data.index.hour\n",
    "    X['dow'] = data.index.dayofweek\n",
    "    X['month'] = data.index.month\n",
    "    X['day'] = data.index.day\n",
    "    \n",
    "    # Codificação cíclica\n",
    "    X['hour_sin'] = np.sin(2*np.pi*X['hour']/24)\n",
    "    X['hour_cos'] = np.cos(2*np.pi*X['hour']/24)\n",
    "    X['dow_sin'] = np.sin(2*np.pi*X['dow']/7)\n",
    "    X['dow_cos'] = np.cos(2*np.pi*X['dow']/7)\n",
    "    X['month_sin'] = np.sin(2*np.pi*X['month']/12)\n",
    "    X['month_cos'] = np.cos(2*np.pi*X['month']/12)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Criar features\n",
    "X, y = create_features(df, n_lags=48)\n",
    "data = pd.concat([X, y.rename('target')], axis=1).dropna()\n",
    "X, y = data.drop('target', axis=1), data['target']\n",
    "\n",
    "print(f'Features criadas: {X.shape[1]}')\n",
    "print(f'Amostras: {len(X)}')\n",
    "print(f'\\nPrimeiras features:')\n",
    "print(X.columns[:10].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e38b257",
   "metadata": {},
   "source": [
    "## 3. Divisão e Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef38d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão treino-teste (80-20)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "print(f'Treino: {len(X_train)} | Teste: {len(X_test)}')\n",
    "\n",
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('\\nDados normalizados!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bcd468",
   "metadata": {},
   "source": [
    "## 4. Grid Search e Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ae774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid de hiperparâmetros\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (128,), (128,64), (128,64,32)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "# MLP base\n",
    "mlp = MLPRegressor(\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Time Series Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print('Iniciando Grid Search...')\n",
    "grid_search = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Usar amostra para acelerar (se dataset grande)\n",
    "sample_size = min(10000, len(X_train_scaled))\n",
    "grid_search.fit(X_train_scaled[:sample_size], y_train.iloc[:sample_size])\n",
    "\n",
    "print('\\nMelhores parâmetros:', grid_search.best_params_)\n",
    "print('Melhor CV MSE:', -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a5352",
   "metadata": {},
   "source": [
    "## 5. Modelo Final e Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6dba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo final com todos os dados de treino\n",
    "best_mlp = grid_search.best_estimator_\n",
    "best_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Previsões\n",
    "y_pred_train = best_mlp.predict(X_train_scaled)\n",
    "y_pred_test = best_mlp.predict(X_test_scaled)\n",
    "\n",
    "print('Previsões concluídas!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f3381",
   "metadata": {},
   "source": [
    "## 6. Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02679dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "mape = np.mean(np.abs((y_test - y_pred_test) / (y_test + 1e-10))) * 100\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('='*50)\n",
    "print('MÉTRICAS - MLP')\n",
    "print('='*50)\n",
    "print(f'RMSE: {rmse:.2f}')\n",
    "print(f'MAE: {mae:.2f}')\n",
    "print(f'MAPE: {mape:.2f}%')\n",
    "print(f'R²: {r2:.4f}')\n",
    "\n",
    "# Visualização\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Predições vs Real\n",
    "axes[0].plot(y_test.index, y_test.values, label='Real', alpha=0.7)\n",
    "axes[0].plot(y_test.index, y_pred_test, label='Previsto', alpha=0.7)\n",
    "axes[0].set_title('MLP - Previsões vs Real')\n",
    "axes[0].set_ylabel('Produção (MW)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot\n",
    "axes[1].scatter(y_test, y_pred_test, alpha=0.5)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Real')\n",
    "axes[1].set_ylabel('Previsto')\n",
    "axes[1].set_title('Real vs Previsto')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/mlp_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77cbef2",
   "metadata": {},
   "source": [
    "## 7. Análise de Resíduos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred_test\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Resíduos ao longo do tempo\n",
    "axes[0,0].plot(y_test.index, residuals)\n",
    "axes[0,0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0,0].set_title('Resíduos ao Longo do Tempo')\n",
    "axes[0,0].set_ylabel('Resíduo')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma\n",
    "axes[0,1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0,1].set_title('Distribuição dos Resíduos')\n",
    "axes[0,1].set_xlabel('Resíduo')\n",
    "axes[0,1].set_ylabel('Frequência')\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot')\n",
    "\n",
    "# Resíduos vs Previsto\n",
    "axes[1,1].scatter(y_pred_test, residuals, alpha=0.5)\n",
    "axes[1,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,1].set_xlabel('Valores Previstos')\n",
    "axes[1,1].set_ylabel('Resíduos')\n",
    "axes[1,1].set_title('Resíduos vs Previstos')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/mlp_residuals.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6dc159",
   "metadata": {},
   "source": [
    "## 8. Salvar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar previsões\n",
    "pred_df = pd.DataFrame({\n",
    "    'real': y_test,\n",
    "    'previsto': y_pred_test\n",
    "}, index=y_test.index)\n",
    "pred_df.to_csv(f'{output_dir}/mlp_predictions.csv')\n",
    "\n",
    "# Salvar métricas\n",
    "results = {\n",
    "    'model': 'MLP',\n",
    "    'dataset': 'solar_france',\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'metrics': {\n",
    "        'mse': float(mse),\n",
    "        'rmse': float(rmse),\n",
    "        'mae': float(mae),\n",
    "        'mape': float(mape),\n",
    "        'r2': float(r2)\n",
    "    },\n",
    "    'n_features': X.shape[1],\n",
    "    'train_size': len(X_train),\n",
    "    'test_size': len(X_test)\n",
    "}\n",
    "\n",
    "with open(f'{output_dir}/mlp_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f'\\n✓ Resultados salvos em {output_dir}/')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
