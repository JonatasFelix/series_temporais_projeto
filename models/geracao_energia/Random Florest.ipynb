{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb549dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0287a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lags(df, lags_list, target_col='Production'):\n",
    "    \"\"\"\n",
    "    Cria defasagens (lags) para transformar a série temporal em um conjunto de dados de regressão.\n",
    "\n",
    "    df (DataFrame): O DataFrame original com a série temporal.\n",
    "    lags_list (list): Lista de defasagens a serem criadas (ex: [1, 24]).\n",
    "    target_col (str): Nome da coluna alvo (y_t).\n",
    "    \"\"\"\n",
    "    # DataFrame auxiliar para armazenar as features.\n",
    "    df_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # 1. Variável Alvo (y_t): O valor da série no momento t.\n",
    "    df_features['y'] = df[target_col].copy()\n",
    "\n",
    "    # 2. Features de Defasagem (X): Valores da série em momentos passados (y_{t-k}).\n",
    "    for lag in lags_list:\n",
    "        # A função shift() move os dados da coluna 'Production' 'lag' posições para baixo,\n",
    "        # criando uma coluna onde cada linha t contém o valor de t-lag.\n",
    "        df_features[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "\n",
    "    # Remove as linhas iniciais que contêm valores NaN (Not a Number) devido ao shift.\n",
    "    # Essas são as observações onde não há dados anteriores suficientes para criar as lags.\n",
    "    df_features.dropna(inplace=True)\n",
    "\n",
    "    # X é a matriz de features, Y é a variável alvo.\n",
    "    X = df_features.drop('y', axis=1)\n",
    "    Y = df_features['y']\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMINHO_RAIZ = Path(os.getcwd()).resolve().parent.parent\n",
    "OUTPUT = CAMINHO_RAIZ / 'out/geracao_energia'\n",
    "os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "solar = pd.read_excel(CAMINHO_RAIZ / 'data' / 'solar france.xlsx')\n",
    "print('Dimensões do dataset:', solar.shape)\n",
    "print('Colunas:', solar.columns.tolist())\n",
    "display(solar.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaab552",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar['Date and Hour'] = pd.to_datetime(solar['Date and Hour'])\n",
    "solar.set_index('Date and Hour', inplace=True)\n",
    "solar.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6e2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = len(solar)\n",
    "p_train = 0.50\n",
    "p_val = 0.25\n",
    "n_train = int(n_obs * p_train)\n",
    "n_val = int(n_obs * p_val)\n",
    "n_test = n_obs - n_train - n_val\n",
    "\n",
    "solar_train = solar.iloc[:n_train]\n",
    "solar_val = solar.iloc[n_train: n_train + n_val]\n",
    "solar_test = solar.iloc[n_train + n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccff19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para dados horários de energia solar, usamos lag de 1 hora e 24 horas (diário)\n",
    "LAG_FEATURES = [1, 24]\n",
    "\n",
    "# Aplicamos a função para criar o conjunto de dados final (X, Y).\n",
    "X_full, Y_full = create_lags(solar, LAG_FEATURES)\n",
    "\n",
    "# Exibimos as primeiras linhas para verificar as features.\n",
    "print(\"Estrutura do Conjunto de Features e Alvo (X e Y):\")\n",
    "print(X_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ca1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_end_date = solar_val.index.max()\n",
    "train_end_date = solar_train.index.max()\n",
    "\n",
    "# X_train e Y_train: Apenas o conjunto de treinamento original.\n",
    "X_train = X_full.loc[:train_end_date]\n",
    "Y_train = Y_full.loc[:train_end_date]\n",
    "\n",
    "# X_val e Y_val: Apenas o conjunto de validação original.\n",
    "X_val = X_full.loc[train_end_date:train_val_end_date].iloc[1:] # Usa .iloc[1:] para remover o ponto de corte duplicado\n",
    "Y_val = Y_full.loc[train_end_date:train_val_end_date].iloc[1:]\n",
    "\n",
    "# X_test e Y_test: O conjunto de teste.\n",
    "X_test = X_full.loc[train_val_end_date:].iloc[1:]\n",
    "Y_test = Y_full.loc[train_val_end_date:].iloc[1:]\n",
    "\n",
    "# X_train_val e Y_train_val: Combinação dos dados para o grid search.\n",
    "X_train_val = pd.concat([X_train, X_val])\n",
    "Y_train_val = pd.concat([Y_train, Y_val])\n",
    "\n",
    "print(f\"\\nNúmero de observações (após remoção de NaNs):\")\n",
    "print(f\"Treinamento: {len(X_train)} | Validação: {len(X_val)} | Teste: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "\n",
    "# Define o espaço de busca para o Random Forest.\n",
    "param_dist = {\n",
    "    # n_estimators: Número de árvores na floresta. Mais árvores = melhor precisão, mais lento.\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    # max_depth: Profundidade máxima de cada árvore. Controla o overfitting.\n",
    "    'max_depth': [5, 10, 15, None], # None significa profundidade total.\n",
    "    # min_samples_leaf: Número mínimo de amostras necessárias em um nó folha.\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    # max_features: Número de features a considerar ao buscar a melhor divisão. 'sqrt' é um bom padrão.\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# TimeSeriesSplit: Divide o conjunto de dados em folds de treino/validação, onde o conjunto\n",
    "# de validação é sempre o mais recente, respeitando a ordem temporal.\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# RandomizedSearchCV: Realiza a busca aleatória.\n",
    "# estimator: O modelo a ser usado (RandomForestRegressor).\n",
    "# param_distributions: O espaço de busca definido acima.\n",
    "# n_iter: Número de combinações de parâmetros a testar.\n",
    "# scoring: A métrica usada para avaliar (MAPE negativo, para otimização).\n",
    "# cv: O método de validação cruzada (TimeSeriesSplit).\n",
    "# random_state: Para reprodutibilidade.\n",
    "# verbose: Nível de detalhe da saída.\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20, # Testaremos 20 combinações\n",
    "    scoring=mape_scorer,\n",
    "    cv=tscv,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1 # Usa todos os processadores disponíveis.\n",
    ")\n",
    "\n",
    "# O método fit() executa a busca no conjunto Treinamento + Validação (X_train_val).\n",
    "random_search.fit(X_train_val, Y_train_val)\n",
    "\n",
    "# best_params_ armazena os hiperparâmetros que obtiveram o melhor score (menor MAPE) na validação cruzada.\n",
    "best_params_ap = random_search.best_params_\n",
    "best_score_ap = -random_search.best_score_ # Reverte o score para o MAPE positivo.\n",
    "\n",
    "print(\"\\n--- Modelo AP (Random Forest) Selecionado ---\")\n",
    "print(f\"Melhores Parâmetros (Random Search): {best_params_ap}\")\n",
    "print(f\"Melhor MAPE na Validação Cruzada: {best_score_ap:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o Random Forest com os melhores parâmetros encontrados.\n",
    "rf_ap_model = RandomForestRegressor(**best_params_ap, random_state=42)\n",
    "\n",
    "# Treinamento final no conjunto X_train_val.\n",
    "rf_ap_model.fit(X_train_val, Y_train_val)\n",
    "\n",
    "# Previsões:\n",
    "# A função predict() gera as previsões y_hat.\n",
    "y_pred_train_ap = rf_ap_model.predict(X_train)\n",
    "y_pred_val_ap = rf_ap_model.predict(X_val)\n",
    "y_pred_test_ap = rf_ap_model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Linha real contínua\n",
    "plt.plot(pd.concat([Y_train_val, Y_val, Y_test]),\n",
    "         label=\"Real\", color=\"black\", linewidth=2)\n",
    "\n",
    "# Previsões destacadas por fase\n",
    "plt.plot(pd.Series(y_pred_train_ap, index=Y_train_val.index[-len(y_pred_train_ap):]),\n",
    "         label=\"Previsto (Treino)\", color=\"blue\", linestyle=\"--\")\n",
    "\n",
    "plt.plot(pd.Series(y_pred_val_ap, index=Y_val.index),\n",
    "         label=\"Previsto (Validação)\", color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "plt.plot(pd.Series(y_pred_test_ap, index=Y_test.index),\n",
    "         label=\"Previsto (Teste)\", color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.title(\"Valores Reais vs Previstos - Treino, Validação e Teste\")\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Produção de Energia Solar\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(OUTPUT / 'Random Florest - Valores Reais vs Previstos - Treino, Validação e Teste.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc27845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica de Erro: Cálculo do EQM e MAPE\n",
    "def evaluate_metrics(y_true, y_pred, name):\n",
    "    \"\"\"Calcula e retorna EQM e MAPE para um conjunto específico.\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return {'Conjunto': name, 'EQM': mse, 'MAPE': mape}\n",
    "\n",
    "results_ap = [\n",
    "    evaluate_metrics(Y_train, y_pred_train_ap, 'Treinamento (AP)'),\n",
    "    evaluate_metrics(Y_val, y_pred_val_ap, 'Validação (AP)'),\n",
    "    evaluate_metrics(Y_test, y_pred_test_ap, 'Teste (AP)')\n",
    "]\n",
    "df = pd.DataFrame(results_ap)\n",
    "\n",
    "# Gráfico de barras lado a lado\n",
    "fig, ax1 = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# EQM\n",
    "ax1[0].bar(df['Conjunto'], df['EQM'], color=['blue','orange','red'])\n",
    "ax1[0].set_title(\"EQM (Erro Quadrático Médio)\")\n",
    "ax1[0].set_ylabel(\"Valor\")\n",
    "\n",
    "# MAPE\n",
    "ax1[1].bar(df['Conjunto'], df['MAPE'], color=['blue','orange','red'])\n",
    "ax1[1].set_title(\"MAPE (Erro Percentual Absoluto Médio)\")\n",
    "ax1[1].set_ylabel(\"Valor\")\n",
    "\n",
    "plt.suptitle(\"Comparação de Métricas por Conjunto\")\n",
    "plt.savefig(OUTPUT / 'Random Florest - Comparação de Métricas por Conjunto.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61288ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = Y_test - y_pred_test_ap\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(residuos, bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Distribuição dos Erros\")\n",
    "plt.xlabel(\"Erro\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.savefig(OUTPUT / 'Random Florest - Distribuição dos Erros.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
