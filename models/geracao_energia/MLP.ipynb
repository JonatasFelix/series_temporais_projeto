{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d02bda63",
   "metadata": {},
   "source": [
    "# Pipeline MLP (Random Search) para previsão de Geração de Energia Solar — Notebook\n",
    "\n",
    "Este notebook implementa um pipeline completo **usando MLP (sklearn.neural_network.MLPRegressor)** e uma busca aleatória (*random search*) de hiperparâmetros. Ele inclui explicações linha-a-linha sobre variáveis, funções, parâmetros e decisões. Salve o arquivo `solar france.xlsx` no mesmo diretório antes de executar as células."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0006f1",
   "metadata": {},
   "source": [
    "## 1) Instruções iniciais\n",
    "\n",
    "- Rode o notebook célula-a-célula.\n",
    "- Se executar no Colab, instale dependências se necessário (por padrão `scikit-learn`, `pandas`, `matplotlib` já vêm no Colab). Se não tiver, execute: `!pip install -q scikit-learn pandas matplotlib openpyxl joblib`.\n",
    "- O notebook fará detecção automática de `target` e `date` e gerará lags se não houver preditores adicionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfe2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import random, time, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df4dc4",
   "metadata": {},
   "source": [
    "## 2) Carregar dados\n",
    "\n",
    "Leia o arquivo Excel `solar france.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMINHO_RAIZ = Path(os.getcwd()).resolve().parent.parent\n",
    "OUTPUT = CAMINHO_RAIZ / 'out_geracao_energia'\n",
    "os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "solar = pd.read_excel(CAMINHO_RAIZ / 'data' / 'solar france.xlsx')\n",
    "print('Dimensões do dataset:', solar.shape)\n",
    "print('Colunas:', solar.columns.tolist())\n",
    "display(solar.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a0b7b",
   "metadata": {},
   "source": [
    "## 3) Transformar série em problema supervisionado (gerar lags)\n",
    "\n",
    "Se não houver preditores além de `date` e `target`, geramos *lags* (defasagens) para criar features a partir da própria série temporal. Aqui criamos 8 lags por padrão (pode ajustar). Cada nova feature `lag_k` representa o valor do target há k períodos atrás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Production'\n",
    "date_col = 'Date and Hour'\n",
    "# criar lags automáticos\n",
    "n_lags = 8\n",
    "if date_col is not None:\n",
    "    solar = solar.sort_values(by=date_col).reset_index(drop=True)\n",
    "for lag in range(1, n_lags+1):\n",
    "    solar[f'lag_{lag}'] = solar[target_col].shift(lag)\n",
    "solar = solar.dropna().reset_index(drop=True)\n",
    "feature_cols = [f'lag_{lag}' for lag in range(1, n_lags+1)]\n",
    "print('Nenhum preditor encontrado além do target/date. Criadas features:', feature_cols)\n",
    "# Exibir amostra\n",
    "display(solar.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82134999",
   "metadata": {},
   "source": [
    "## 4) Separar X (features) e y (target) e criar split (treino/validação/teste)\n",
    "\n",
    "usamos split cronológico: 50% treino, 25% validação, 25% teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir X e y\n",
    "X = solar[feature_cols].copy()\n",
    "y = solar[target_col].copy()\n",
    "print('Shapes: X=', X.shape, ' y=', y.shape)\n",
    "\n",
    "# Split cronológico\n",
    "df_sorted = solar.sort_values(by=date_col).reset_index(drop=True)\n",
    "X_sorted = df_sorted[feature_cols]\n",
    "y_sorted = df_sorted[target_col]\n",
    "n = len(df_sorted)\n",
    "n_train = int(n * 0.50)\n",
    "n_val = int(n * 0.25)\n",
    "X_train = X_sorted.iloc[:n_train].reset_index(drop=True)\n",
    "y_train = y_sorted.iloc[:n_train].reset_index(drop=True)\n",
    "X_val = X_sorted.iloc[n_train:n_train+n_val].reset_index(drop=True)\n",
    "y_val = y_sorted.iloc[n_train:n_train+n_val].reset_index(drop=True)\n",
    "X_test = X_sorted.iloc[n_train+n_val:].reset_index(drop=True)\n",
    "y_test = y_sorted.iloc[n_train+n_val:].reset_index(drop=True)\n",
    "print(f'Split cronológico: train={len(X_train)}, val={len(X_val)}, test={len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1936f14",
   "metadata": {},
   "source": [
    "## 6) Pré-processamento\n",
    "\n",
    "- **Imputação**: SimpleImputer(strategy='median') para colunas numéricas (robusto a outliers).\n",
    "- **Escalonamento**: StandardScaler — redes MLP convergem melhor com features padronizadas.\n",
    "- **OneHotEncoder** para categóricas, se houver.\n",
    "\n",
    "Usamos `ColumnTransformer` para aplicar as transformações apenas aos tipos correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar tipos\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "\n",
    "print('numeric_cols:', numeric_cols)\n",
    "print('categorical_cols:', categorical_cols)\n",
    "\n",
    "num_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                  ('scaler', StandardScaler())])\n",
    "cat_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                  ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, numeric_cols),\n",
    "                                               ('cat', cat_transformer, categorical_cols)],\n",
    "                                 remainder='drop')\n",
    "\n",
    "# Ajustar apenas no treino (evita vazamento)\n",
    "preprocessor.fit(X_train)\n",
    "X_train_proc = preprocessor.transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "print('Formas após pré-processamento:',\n",
    "      'X_train_proc=', X_train_proc.shape,\n",
    "      'X_val_proc=', X_val_proc.shape,\n",
    "      'X_test_proc=', X_test_proc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77bcd86",
   "metadata": {},
   "source": [
    "## 7) Random Search (busca aleatória) para MLPRegressor\n",
    "\n",
    "Explicações dos hiperparâmetros que vamos variar:\n",
    "- `hidden_layer_sizes`: tupla com número de neurônios por camada (ex: (64, 32) → 2 camadas ocultas)\n",
    "- `activation`: função de ativação (relu, tanh)\n",
    "- `alpha`: termo de regularização L2 (evita overfitting)\n",
    "- `learning_rate_init`: taxa inicial de aprendizado\n",
    "- `solver`: algoritmo de otimização ('adam' recomendado)\n",
    "- `batch_size`: tamanho do batch\n",
    "\n",
    "Estratégia: amostrar aleatoriamente N combinações do espaço e treinar cada modelo no conjunto de treino, avaliando no conjunto de validação. Selecionamos o modelo com menor MSE na validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espaço de busca\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(16,), (32,), (64,), (64,32), (128,64)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2],\n",
    "    'learning_rate_init': [1e-2, 1e-3, 1e-4],\n",
    "    'solver': ['adam'],  # restringimos a 'adam' por estabilidade\n",
    "    'batch_size': [16, 32, 64]\n",
    "}\n",
    "\n",
    "def sample_params(grid):\n",
    "    return {k: random.choice(v) for k, v in grid.items()}\n",
    "\n",
    "n_iter = 24  # número de combinações aleatórias a testar (ajuste conforme poder de processamento)\n",
    "results = []\n",
    "best = None\n",
    "best_val_mse = float('inf')\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(n_iter):\n",
    "    params = sample_params(param_grid)\n",
    "    print(f'Iter {i+1}/{n_iter} -> {params}')\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "                       activation=params['activation'],\n",
    "                       alpha=params['alpha'],\n",
    "                       learning_rate_init=params['learning_rate_init'],\n",
    "                       solver=params['solver'],\n",
    "                       batch_size=params['batch_size'],\n",
    "                       max_iter=500,\n",
    "                       early_stopping=True,\n",
    "                       n_iter_no_change=20,\n",
    "                       tol=1e-5,\n",
    "                       random_state=42,\n",
    "                       verbose=False)\n",
    "    try:\n",
    "        mlp.fit(X_train_proc, y_train.values.ravel())\n",
    "    except Exception as e:\n",
    "        print('  Treino falhou para esses hiperparâmetros:', e)\n",
    "        continue\n",
    "    # Avaliar no conjunto de validação\n",
    "    y_val_pred = mlp.predict(X_val_proc)\n",
    "    val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "    # MAPE poderá ser calculado depois para robustez\n",
    "    print(f'  Val MSE = {val_mse:.4f}')\n",
    "    results.append({'params': params, 'val_mse': val_mse, 'model': mlp})\n",
    "    if val_mse < best_val_mse:\n",
    "        best_val_mse = val_mse\n",
    "        best = results[-1]\n",
    "end_time = time.time()\n",
    "print('\\nRandom search concluído em {:.1f} s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99502134",
   "metadata": {},
   "source": [
    "## 8) Seleção do melhor modelo e avaliação final (treino/val/test)\n",
    "\n",
    "Calculamos MSE e MAPE para treino, validação e teste no melhor modelo encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar melhor\n",
    "if best is None:\n",
    "    raise RuntimeError('Nenhum modelo treinado com sucesso.')\n",
    "\n",
    "best_params = best['params']\n",
    "best_model = best['model']\n",
    "print('Melhor hiperparâmetros encontrados:', best_params)\n",
    "print('Val MSE do melhor:', best['val_mse'])\n",
    "\n",
    "# Função segura de MAPE (evita divisão por zero)\n",
    "def safe_mape(y_true, y_pred):\n",
    "    y_true = np.array(y_true).astype(float)\n",
    "    y_pred = np.array(y_pred).astype(float)\n",
    "    eps = 1e-8\n",
    "    denom = np.where(np.abs(y_true) < eps, eps, y_true)\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100.0\n",
    "\n",
    "# Previsões\n",
    "y_train_pred = best_model.predict(X_train_proc)\n",
    "y_val_pred = best_model.predict(X_val_proc)\n",
    "y_test_pred = best_model.predict(X_test_proc)\n",
    "\n",
    "# Métricas\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mape_train = safe_mape(y_train, y_train_pred)\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "mape_val = safe_mape(y_val, y_val_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mape_test = safe_mape(y_test, y_test_pred)\n",
    "\n",
    "print('\\nMétricas finais:')\n",
    "print(f'Train - MSE: {mse_train:.4f}, MAPE: {mape_train:.4f}%')\n",
    "print(f'Val   - MSE: {mse_val:.4f}, MAPE: {mape_val:.4f}%')\n",
    "print(f'Test  - MSE: {mse_test:.4f}, MAPE: {mape_test:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acf80e",
   "metadata": {},
   "source": [
    "## 9) Gráficos: reais vs previstos e histogramas de resíduos\n",
    "\n",
    "Mostramos gráficos para treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0514ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos (um por célula)\n",
    "def plot_actual_vs_pred(y_true, y_pred, title):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    plt.xlabel('Valor real')\n",
    "    plt.ylabel('Valor previsto')\n",
    "    plt.title(title)\n",
    "    mn = min(np.min(y_true), np.min(y_pred))\n",
    "    mx = max(np.max(y_true), np.max(y_pred))\n",
    "    plt.plot([mn,mx],[mn,mx], linewidth=1)\n",
    "    plt.savefig(OUTPUT/ f'MLP - {title}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_residuals_hist(y_true, y_pred, title):\n",
    "    residuals = y_true - y_pred\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.hist(residuals, bins=30)\n",
    "    plt.xlabel('Resíduo')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.title(title)\n",
    "    plt.savefig(OUTPUT/ f'MLP - {title}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Treino\n",
    "plot_actual_vs_pred(y_train, y_train_pred, 'Treino - Reais vs Previstas')\n",
    "plot_residuals_hist(y_train, y_train_pred, 'Treino - Resíduos')\n",
    "\n",
    "# Validação\n",
    "plot_actual_vs_pred(y_val, y_val_pred, 'Validação - Reais vs Previstas')\n",
    "plot_residuals_hist(y_val, y_val_pred, 'Validação - Resíduos')\n",
    "\n",
    "# Teste\n",
    "plot_actual_vs_pred(y_test, y_test_pred, 'Teste - Reais vs Previstas')\n",
    "plot_residuals_hist(y_test, y_test_pred, 'Teste - Resíduos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce13708",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Treinamento', 'Validação', 'Teste']\n",
    "mse_values = [mse_train, mse_val, mse_test]\n",
    "mape_values = [mape_train, mape_val, mape_test]\n",
    "\n",
    "# Criar figura com 2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# --- Gráfico 1: MSE ---\n",
    "axes[0].bar(datasets, mse_values, color=['#4CAF50', '#FFC107', '#2196F3'])\n",
    "axes[0].set_title('Comparação do MSE (Erro Quadrático Médio)')\n",
    "axes[0].set_ylabel('MSE')\n",
    "axes[0].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# --- Gráfico 2: MAPE ---\n",
    "axes[1].bar(datasets, mape_values, color=['#4CAF50', '#FFC107', '#2196F3'])\n",
    "axes[1].set_title('Comparação do MAPE (Erro Percentual Absoluto Médio)')\n",
    "axes[1].set_ylabel('MAPE (%)')\n",
    "axes[1].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.suptitle('Comparação de desempenho do modelo MLP', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT / 'MLP - Comparação de desempenho do modelo.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
