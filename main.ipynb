{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4b3ebfc927b5c7",
   "metadata": {},
   "source": [
    "1) Imports, Config & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:22:58.605307Z",
     "start_time": "2025-10-07T00:22:58.598222Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, math, json, warnings\n",
    "import os\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1774c15a51d18dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:22:58.657033Z",
     "start_time": "2025-10-07T00:22:58.641854Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Reprodutibilidade\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Pasta de dados e de saída\n",
    "DATA_DIR = os.path.join(os.getcwd(), \"data\")\n",
    "OUT_DIR = os.path.join(os.getcwd(), \"out\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Hiperparâmetros globais (você pode ajustar depois)\n",
    "CFG = {\n",
    "    \"apply_log\": False,\n",
    "    \"split_ratios\": (0.5, 0.25, 0.25),\n",
    "    \"freq\": None,              # ex: \"D\",\"W\",\"M\" ou None p/ inferir\n",
    "    \"force_regular\": False,    # True => reindexa pela frequência e interpola\n",
    "\n",
    "    # Sazonalidade (se souber, informe; senão deixe None)\n",
    "    \"seasonal_period\": None,   # ex: 7, 12, 24, 52\n",
    "\n",
    "    # Busca ARIMA/SARIMA\n",
    "    \"arima_pdq_grid\": [(0,1,1), (1,1,1), (2,1,1)],\n",
    "    \"arima_PDQ_grid\": [(0,0,0), (1,1,1)],\n",
    "\n",
    "    # KNN\n",
    "    \"lags_grid\": [12],               # nº máximo de lags p/ features\n",
    "    \"rolling_feats\": [None, 6],      # stats móveis\n",
    "    \"knn_n_neighbors\": [5, 15, 25],\n",
    "    \"knn_weights\": [\"uniform\", \"distance\"],\n",
    "    \"knn_p\": [1, 2],\n",
    "\n",
    "    # VGG-1D\n",
    "    \"use_vgg\": True,\n",
    "    \"vgg_windows\": [12, 24],\n",
    "    \"vgg_filters\": [32, 64],\n",
    "    \"vgg_dropout\": [0.0, 0.2],\n",
    "    \"vgg_epochs\": 40,\n",
    "    \"vgg_batch\": 32,\n",
    "    \"vgg_patience\": 6,\n",
    "\n",
    "    # Híbridos\n",
    "    \"hybrid_residual\": True,\n",
    "    \"hybrid_ensemble\": True,\n",
    "    \"ensemble_weight_step\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb917bb6cd126218",
   "metadata": {},
   "source": [
    "2) Utilidades de E/S, métricas e gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c29804dea5b654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:22:58.693425Z",
     "start_time": "2025-10-07T00:22:58.669823Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "def mse(y, yhat):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    return float(mean_squared_error(y, yhat))\n",
    "\n",
    "def mape(y, yhat, eps=1e-8):\n",
    "    y, yhat = np.asarray(y), np.asarray(yhat)\n",
    "    return float(np.mean(np.abs((y - yhat) / np.maximum(np.abs(y), eps))) * 100)\n",
    "\n",
    "def save_plot(name):\n",
    "    path = os.path.join(OUT_DIR, f\"{name}.png\")\n",
    "    plt.savefig(path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_fit(idx, y_true, y_pred, title, name):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(idx, y_true, label=\"Observado\")\n",
    "    plt.plot(idx, y_pred, label=\"Previsto\")\n",
    "    plt.title(title); plt.xlabel(\"Tempo\"); plt.legend()\n",
    "    save_plot(name)\n",
    "\n",
    "def export_json(obj: dict, name: str):\n",
    "    with open(os.path.join(OUT_DIR, f\"{name}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360e34f8f86559e",
   "metadata": {},
   "source": [
    "3) Descobrir datasets e perguntar qual usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5808e0c2ee193a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:23:01.190820Z",
     "start_time": "2025-10-07T00:22:58.704599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets encontrados:\n",
      "\n",
      "0: chuva_fortaleza.xlsx\n",
      "1: dengue_pernambuco.xlsx\n",
      "2: household_consumption.xlsx\n",
      "3: solar france.xlsx\n",
      "\n",
      "Você escolheu: dengue_pernambuco.xlsx\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def list_datasets(data_dir=DATA_DIR):\n",
    "    files = []\n",
    "    for fn in os.listdir(data_dir):\n",
    "        if fn.lower().endswith((\".xlsx\", \".csv\")):\n",
    "            files.append(os.path.join(data_dir, fn))\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "files = list_datasets()\n",
    "assert files, \"Nenhum arquivo .xlsx/.csv encontrado em ./data\"\n",
    "\n",
    "print(\"Datasets encontrados:\\n\")\n",
    "for i, f in enumerate(files):\n",
    "    print(f\"{i}: {os.path.basename(f)}\")\n",
    "\n",
    "# Pergunta ao usuário qual usar\n",
    "while True:\n",
    "    try:\n",
    "        choice = int(input(\"\\nDigite o índice do dataset desejado: \").strip())\n",
    "        assert 0 <= choice < len(files)\n",
    "        DATA_PATH = files[choice]\n",
    "        break\n",
    "    except Exception:\n",
    "        print(\"Índice inválido. Tente novamente.\")\n",
    "\n",
    "print(f\"\\nVocê escolheu: {os.path.basename(DATA_PATH)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5b30dd643dc25",
   "metadata": {},
   "source": [
    "4) Detecção automática das colunas (data e alvo) + carregamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fca03b6e38e0da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:23:02.157082Z",
     "start_time": "2025-10-07T00:23:01.507808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna de data detectada: semana\n",
      "Coluna alvo detectada:    valor\n",
      "N observações: 887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "semana\n",
       "2000-01-08    686.0\n",
       "2000-01-15    611.0\n",
       "2000-01-22    614.0\n",
       "2000-01-29    598.0\n",
       "2000-02-05    785.0\n",
       "Name: valor, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "from datetime import datetime\n",
    "\n",
    "TARGET_HINTS = [\n",
    "    # comuns em PT/EN\n",
    "    \"valor\",\"value\",\"target\",\"y\",\"serie\",\"series\",\"mm\",\"chuva\",\"precipit\",\"precip\",\"rain\",\n",
    "    \"kwh\",\"energia\",\"power\",\"load\",\"demand\",\"production\",\"cases\",\"casos\",\"incid\",\"count\", \"consumption\"\n",
    "]\n",
    "\n",
    "def guess_datetime_col(df: pd.DataFrame) -> Optional[str]:\n",
    "    # heurística: 1ª coluna que converte para datetime com sucesso e com poucos NaNs\n",
    "    best = None\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            s = pd.to_datetime(df[c], errors=\"raise\")\n",
    "            if s.notna().mean() > 0.9:\n",
    "                best = c\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    return best\n",
    "\n",
    "def guess_target_col(df: pd.DataFrame, date_col: Optional[str]) -> str:\n",
    "    # 1) preferir nomes que batem com TARGET_HINTS e sejam numéricos\n",
    "    lower_map = {c: c.lower() for c in df.columns}\n",
    "    for c in df.columns:\n",
    "        lc = lower_map[c]\n",
    "        if any(h in lc for h in TARGET_HINTS) and pd.api.types.is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    # 2) se não achou, pegar a coluna numérica com maior variância (ignora a de data)\n",
    "    cand = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and c != date_col]\n",
    "    if not cand:\n",
    "        raise ValueError(\"Não há colunas numéricas para usar como alvo.\")\n",
    "    return max(cand, key=lambda col: np.nanvar(pd.to_numeric(df[col], errors=\"coerce\")))\n",
    "\n",
    "def load_series_auto(path: str) -> Tuple[pd.Series, str, str]:\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path)\n",
    "    else:\n",
    "        df = pd.read_excel(path, sheet_name=0, engine=\"openpyxl\")\n",
    "\n",
    "    date_col = guess_datetime_col(df)\n",
    "    if date_col is None:\n",
    "        raise ValueError(\"Não consegui detectar a coluna de datas. Informe uma no arquivo ou converta previamente.\")\n",
    "\n",
    "    target_col = guess_target_col(df, date_col)\n",
    "    s = df[[date_col, target_col]].copy()\n",
    "    s[date_col] = pd.to_datetime(s[date_col])\n",
    "    s = s.dropna().sort_values(date_col).set_index(date_col)[target_col].astype(float)\n",
    "\n",
    "    # Regularização opcional\n",
    "    freq = CFG[\"freq\"]\n",
    "    if freq is None:\n",
    "        try: freq = pd.infer_freq(s.index)\n",
    "        except: freq = None\n",
    "    if CFG[\"force_regular\"] and freq:\n",
    "        idx = pd.date_range(s.index.min(), s.index.max(), freq=freq)\n",
    "        s = s.reindex(idx).interpolate(limit_direction=\"both\")\n",
    "\n",
    "    return s, date_col, target_col\n",
    "\n",
    "y_raw, detected_date_col, detected_target_col = load_series_auto(DATA_PATH)\n",
    "print(f\"Coluna de data detectada: {detected_date_col}\")\n",
    "print(f\"Coluna alvo detectada:    {detected_target_col}\")\n",
    "print(f\"N observações: {len(y_raw)}\")\n",
    "y_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5118d83c9c91bbf",
   "metadata": {},
   "source": [
    "5) Transformações, testes básicos e split 50/25/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f42d5b89a46380e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:23:02.548374Z",
     "start_time": "2025-10-07T00:23:02.531631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split -> train=443, val=221, test=223\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def apply_log_if_needed(y: pd.Series):\n",
    "    if CFG[\"apply_log\"]:\n",
    "        return np.log1p(y.clip(lower=0)), \"log1p\"\n",
    "    return y.copy(), None\n",
    "\n",
    "def invert_transform(pred, trans):\n",
    "    if trans == \"log1p\": return np.expm1(pred)\n",
    "    return pred\n",
    "\n",
    "def time_split(y: pd.Series, ratios=(0.5,0.25,0.25)):\n",
    "    n = len(y)\n",
    "    n_tr = int(n*ratios[0]); n_val = int(n*ratios[1])\n",
    "    y_tr = y.iloc[:n_tr]\n",
    "    y_va = y.iloc[n_tr:n_tr+n_val]\n",
    "    y_te = y.iloc[n_tr+n_val:]\n",
    "    return y_tr, y_va, y_te\n",
    "\n",
    "y, trans = apply_log_if_needed(y_raw)\n",
    "y_train, y_val, y_test = time_split(y, CFG[\"split_ratios\"])\n",
    "\n",
    "print(f\"Split -> train={len(y_train)}, val={len(y_val)}, test={len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3341a7b4f7a8d",
   "metadata": {},
   "source": [
    "6) ARIMA/SARIMA (Box–Jenkins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5a0aa995824c57a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:23:19.008342Z",
     "start_time": "2025-10-07T00:23:03.747393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joncu\\OneDrive\\Documentos\\series_temporais_projeto\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency W-SAT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\joncu\\OneDrive\\Documentos\\series_temporais_projeto\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency W-SAT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\joncu\\OneDrive\\Documentos\\series_temporais_projeto\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency W-SAT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\joncu\\OneDrive\\Documentos\\series_temporais_projeto\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency W-SAT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\joncu\\OneDrive\\Documentos\\series_temporais_projeto\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency W-SAT will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\joncu\\OneDrive\\Documentos\\series_temporais_projeto\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency W-SAT will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'mse': 47957.296113203774, 'mape': 63.91040942000483}, 'val': {'mse': 11057.835821459566, 'mape': 44.8364965027737}, 'test': {'mse': 175078.45267785882, 'mape': 27.590372979159472}, 'order': (2, 1, 1), 'seasonal': (0, 0, 0, 0), 'aic': 6017.739370263315, 'lb_pmin': 0.00040782095795065254}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "class ArimaPick:\n",
    "    def __init__(self, order, seas, aic, lb_pmin, model):\n",
    "        self.order, self.seas = order, seas\n",
    "        self.aic, self.lb_pmin, self.model = aic, lb_pmin, model\n",
    "\n",
    "def fit_arima_grid(y_tr: pd.Series, s: Optional[int]):\n",
    "    best = None\n",
    "    for (p,d,q) in CFG[\"arima_pdq_grid\"]:\n",
    "        for (P,D,Q) in (CFG[\"arima_PDQ_grid\"] if s else [(0,0,0)]):\n",
    "            seas = (P,D,Q,s) if s else (0,0,0,0)\n",
    "            try:\n",
    "                m = SARIMAX(y_tr, order=(p,d,q), seasonal_order=seas).fit(disp=False)\n",
    "                resid = m.resid.dropna()\n",
    "                lb = acorr_ljungbox(resid, lags=[10,15,20], return_df=True)[\"lb_pvalue\"].min()\n",
    "                pick = ArimaPick((p,d,q), seas, float(m.aic), float(lb), m)\n",
    "                if (best is None) or (pick.aic < best.aic - 1e-6) or \\\n",
    "                   (abs(pick.aic - best.aic) < 1e-6 and pick.lb_pmin > best.lb_pmin):\n",
    "                    best = pick\n",
    "            except:\n",
    "                continue\n",
    "    if best is None: raise RuntimeError(\"ARIMA/SARIMA não encontrado.\")\n",
    "    return best\n",
    "\n",
    "def arima_walk(res, y_next: pd.Series):\n",
    "    preds=[]\n",
    "    for yt in y_next.values:\n",
    "        pm = res.get_forecast(steps=1).predicted_mean.iloc[-1]\n",
    "        preds.append(pm)\n",
    "        res = res.append(endog=[yt], refit=False)\n",
    "    return np.array(preds)\n",
    "\n",
    "s = CFG[\"seasonal_period\"]\n",
    "ar_best = fit_arima_grid(y_train, s)\n",
    "pred_train_in = ar_best.model.get_prediction().predicted_mean.loc[y_train.index].values\n",
    "pred_val_ar = arima_walk(ar_best.model, y_val)\n",
    "pred_test_ar = arima_walk(ar_best.model, y_test)\n",
    "\n",
    "# escala original p/ métricas\n",
    "ytr_p = invert_transform(y_train.values, trans)\n",
    "yva_p = invert_transform(y_val.values, trans)\n",
    "yte_p = invert_transform(y_test.values, trans)\n",
    "ar_tr_p = invert_transform(pred_train_in, trans)\n",
    "ar_va_p = invert_transform(pred_val_ar, trans)\n",
    "ar_te_p = invert_transform(pred_test_ar, trans)\n",
    "\n",
    "ar_metrics = {\n",
    "    \"train\": {\"mse\": mse(ytr_p, ar_tr_p), \"mape\": mape(ytr_p, ar_tr_p)},\n",
    "    \"val\":   {\"mse\": mse(yva_p, ar_va_p), \"mape\": mape(yva_p, ar_va_p)},\n",
    "    \"test\":  {\"mse\": mse(yte_p, ar_te_p), \"mape\": mape(yte_p, ar_te_p)},\n",
    "    \"order\": ar_best.order, \"seasonal\": ar_best.seas, \"aic\": ar_best.aic, \"lb_pmin\": ar_best.lb_pmin\n",
    "}\n",
    "print(ar_metrics)\n",
    "\n",
    "plot_fit(y_train.index, y_train.values, pred_train_in, f\"ARIMA {ar_best.order} {ar_best.seas} - Treino\", \"arima_train\")\n",
    "plot_fit(y_val.index, y_val.values, pred_val_ar, \"ARIMA - Validação\", \"arima_val\")\n",
    "plot_fit(y_test.index, y_test.values, pred_test_ar, \"ARIMA - Teste\", \"arima_test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a438d35511fe83",
   "metadata": {},
   "source": [
    "7) KNN (AM clássico) – lags + rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe94e878e185d81e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:23:22.531348Z",
     "start_time": "2025-10-07T00:23:19.095780Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def make_supervised(y: pd.Series, max_lag: int, rolling: Optional[int]):\n",
    "    df = pd.DataFrame({\"y\": y})\n",
    "    for L in range(1, max_lag+1):\n",
    "        df[f\"lag_{L}\"] = df[\"y\"].shift(L)\n",
    "    if rolling and rolling>1:\n",
    "        df[f\"roll_mean_{rolling}\"] = df[\"y\"].shift(1).rolling(rolling).mean()\n",
    "        df[f\"roll_std_{rolling}\"]  = df[\"y\"].shift(1).rolling(rolling).std()\n",
    "    return df.dropna()\n",
    "\n",
    "def split_sup(df_sup, idx_splits):\n",
    "    it_tr, it_val, it_te = idx_splits\n",
    "    X, y = df_sup.drop(columns=[\"y\"]), df_sup[\"y\"]\n",
    "    Xtr = X.loc[X.index.intersection(it_tr)]; ytr = y.loc[Xtr.index]\n",
    "    Xva = X.loc[X.index.intersection(it_val)]; yva = y.loc[Xva.index]\n",
    "    Xte = X.loc[X.index.intersection(it_te)]; yte = y.loc[Xte.index]\n",
    "    return Xtr, ytr, Xva, yva, Xte, yte\n",
    "\n",
    "def knn_search(y: pd.Series, idx_splits):\n",
    "    best={\"score\": math.inf}\n",
    "    for lags in CFG[\"lags_grid\"]:\n",
    "        for roll in CFG[\"rolling_feats\"]:\n",
    "            sup = make_supervised(y, lags, roll)\n",
    "            Xtr,ytr,Xva,yva,Xte,yte = split_sup(sup, idx_splits)\n",
    "            if len(Xva)==0 or len(Xte)==0: continue\n",
    "            grid = ParameterGrid({\n",
    "                \"n_neighbors\": CFG[\"knn_n_neighbors\"],\n",
    "                \"weights\": CFG[\"knn_weights\"],\n",
    "                \"p\": CFG[\"knn_p\"],\n",
    "            })\n",
    "            for params in grid:\n",
    "                model = Pipeline([\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"knn\", KNeighborsRegressor(**params))\n",
    "                ])\n",
    "                model.fit(Xtr, ytr)\n",
    "                p_tr = model.predict(Xtr); p_va = model.predict(Xva); p_te = model.predict(Xte)\n",
    "                score = mse(yva, p_va)\n",
    "                if score < best[\"score\"]:\n",
    "                    best = {\n",
    "                        \"score\": score, \"lags\": lags, \"rolling\": roll, \"params\": params,\n",
    "                        \"preds\": {\"train\": p_tr, \"val\": p_va, \"test\": p_te},\n",
    "                        \"truth\": {\"train\": ytr, \"val\": yva, \"test\": yte},\n",
    "                        \"model\": model\n",
    "                    }\n",
    "    if best[\"score\"]==math.inf: raise RuntimeError(\"KNN não válido.\")\n",
    "    return best\n",
    "\n",
    "idx_splits = (y_train.index, y_val.index, y_test.index)\n",
    "knn_best = knn_search(y, idx_splits)\n",
    "\n",
    "plot_fit(knn_best[\"truth\"][\"train\"].index, knn_best[\"truth\"][\"train\"].values, knn_best[\"preds\"][\"train\"],\n",
    "         \"KNN - Treino\", \"knn_train\")\n",
    "plot_fit(knn_best[\"truth\"][\"val\"].index, knn_best[\"truth\"][\"val\"].values, knn_best[\"preds\"][\"val\"],\n",
    "         \"KNN - Validação\", \"knn_val\")\n",
    "plot_fit(knn_best[\"truth\"][\"test\"].index, knn_best[\"truth\"][\"test\"].values, knn_best[\"preds\"][\"test\"],\n",
    "         \"KNN - Teste\", \"knn_test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b65336ce1d3a4",
   "metadata": {},
   "source": [
    "8) VGG-1D (AP) – CNN estilo VGG para séries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "103dcc793850a6ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:29:43.030823Z",
     "start_time": "2025-10-07T00:29:43.024162Z"
    }
   },
   "outputs": [],
   "source": [
    "# === IMPORTS DIRETOS ===\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "\n",
    "# === FUNÇÃO AUXILIAR PARA IMPORTAÇÃO SEGURA DO TENSORFLOW ===\n",
    "def try_import_tf():\n",
    "    \"\"\"\n",
    "    Tenta importar TensorFlow e seus componentes necessários.\n",
    "    Retorna uma tupla com os imports ou None se falhar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras import Sequential\n",
    "        from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Flatten\n",
    "        from tensorflow.keras.callbacks import EarlyStopping\n",
    "        return (tf, Sequential, Conv1D, MaxPooling1D, Dropout, Dense, Flatten, EarlyStopping)\n",
    "    except ImportError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "802291fa1a64f25d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:31:43.826013Z",
     "start_time": "2025-10-07T00:29:48.384105Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_windows(y: pd.Series, window: int):\n",
    "    arr = y.values.astype(\"float32\")\n",
    "    X, Y, idx = [], [], []\n",
    "    for i in range(window, len(arr)):\n",
    "        X.append(arr[i-window:i]); Y.append(arr[i]); idx.append(y.index[i])\n",
    "    X = np.array(X).reshape(-1, window, 1); Y = np.array(Y); idx = pd.DatetimeIndex(idx)\n",
    "    return X, Y, idx\n",
    "\n",
    "def vgg1d_block(model, Conv1D, filters):\n",
    "    model.add(Conv1D(filters, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv1D(filters, 3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(2))\n",
    "\n",
    "def vgg_search(y: pd.Series, idx_splits):\n",
    "    if not CFG[\"use_vgg\"]:\n",
    "        return {\"disabled\": True}\n",
    "    tfp = try_import_tf()\n",
    "    if tfp is None:\n",
    "        return {\"disabled\": True, \"reason\": \"TensorFlow não encontrado (instale tensorflow>=2.12).\"}\n",
    "    tf, Sequential, Conv1D, MaxPooling1D, Dropout, Dense, Flatten, EarlyStopping = tfp\n",
    "\n",
    "    best={\"score\": math.inf}\n",
    "    for window in CFG[\"vgg_windows\"]:\n",
    "        X, Y, idx_all = build_windows(y, window)\n",
    "        it_tr, it_val, it_te = idx_splits\n",
    "        it_tr2 = idx_all.intersection(it_tr); it_val2 = idx_all.intersection(it_val); it_te2 = idx_all.intersection(it_te)\n",
    "        def take(ix):\n",
    "            m = np.isin(idx_all, ix)\n",
    "            return X[m], Y[m]\n",
    "        Xtr, ytr = take(it_tr2); Xva, yva = take(it_val2); Xte, yte = take(it_te2)\n",
    "        if len(Xva)==0 or len(Xte)==0: continue\n",
    "\n",
    "        for f0 in CFG[\"vgg_filters\"]:\n",
    "            for dr in CFG[\"vgg_dropout\"]:\n",
    "                model = Sequential()\n",
    "                vgg1d_block(model, Conv1D, f0)\n",
    "                vgg1d_block(model, Conv1D, f0*2)\n",
    "                vgg1d_block(model, Conv1D, f0*2)\n",
    "                if dr>0: model.add(Dropout(dr))\n",
    "                model.add(Flatten()); model.add(Dense(64, activation=\"relu\"))\n",
    "                model.add(Dense(1))\n",
    "                model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "                es = EarlyStopping(monitor=\"val_loss\", patience=CFG[\"vgg_patience\"],\n",
    "                                   restore_best_weights=True, verbose=0)\n",
    "                model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
    "                          epochs=CFG[\"vgg_epochs\"], batch_size=CFG[\"vgg_batch\"], verbose=0, callbacks=[es])\n",
    "                p_tr = model.predict(Xtr, verbose=0).ravel()\n",
    "                p_va = model.predict(Xva, verbose=0).ravel()\n",
    "                p_te = model.predict(Xte, verbose=0).ravel()\n",
    "                score = mse(yva, p_va)\n",
    "                if score < best[\"score\"]:\n",
    "                    best = {\"score\": score, \"window\": window, \"filters\": f0, \"dropout\": dr,\n",
    "                            \"preds\": {\"train\": p_tr, \"val\": p_va, \"test\": p_te},\n",
    "                            \"truth\": {\"train\": ytr, \"val\": yva, \"test\": yte},\n",
    "                            \"idx\": {\"train\": it_tr2, \"val\": it_val2, \"test\": it_te2}}\n",
    "    if best[\"score\"]==math.inf:\n",
    "        return {\"disabled\": True, \"reason\": \"Sem janela VGG válida.\"}\n",
    "    return best\n",
    "\n",
    "vgg_best = vgg_search(y, idx_splits)\n",
    "if not vgg_best.get(\"disabled\", False):\n",
    "    # gráficos usando os índices do VGG\n",
    "    idv = vgg_best[\"idx\"]\n",
    "    plot_fit(idv[\"train\"], vgg_best[\"truth\"][\"train\"], vgg_best[\"preds\"][\"train\"], \"VGG-1D - Treino\", \"vgg_train\")\n",
    "    plot_fit(idv[\"val\"],   vgg_best[\"truth\"][\"val\"],   vgg_best[\"preds\"][\"val\"],   \"VGG-1D - Validação\", \"vgg_val\")\n",
    "    plot_fit(idv[\"test\"],  vgg_best[\"truth\"][\"test\"],  vgg_best[\"preds\"][\"test\"],  \"VGG-1D - Teste\", \"vgg_test\")\n",
    "else:\n",
    "    print(vgg_best.get(\"reason\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb1a9ff64cb26d",
   "metadata": {},
   "source": [
    "9) Modelos Híbridos (Residual Stacking + Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d36c5b3162289d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:36:56.101907Z",
     "start_time": "2025-10-07T00:36:54.985378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'residual': {'test_pred': array([ 9.89567611e+01,  1.00402775e+02,  5.54769812e+01,  1.04032305e+02,\n",
       "          4.86102950e+01,  1.14967083e+02,  3.15942961e+01,  8.72064240e+01,\n",
       "          2.27141771e+01,  5.85019682e+01,  1.03246962e+02,  2.75843222e+01,\n",
       "          6.36385209e+00,  7.11396130e+01,  6.04305446e+01,  8.27892970e+01,\n",
       "          9.01059454e+01,  5.32106705e+01,  1.02459531e+02,  1.11743163e+02,\n",
       "          1.32511667e+02,  1.51432535e+02,  1.30877247e+02,  2.04263401e+02,\n",
       "          2.11775653e+02,  2.23311716e+02,  3.06627868e+02,  4.09606047e+02,\n",
       "          3.55223251e+02,  3.36920807e+02,  3.61150406e+02,  4.17536166e+02,\n",
       "          2.58675722e+02,  3.20683147e+02,  3.11256646e+02,  2.50219717e+02,\n",
       "          2.10631461e+02,  1.22654060e+02,  1.41646226e+02,  1.50496273e+02,\n",
       "          1.14863096e+02,  1.71132494e+02,  1.10751297e+02,  1.60230425e+02,\n",
       "          1.44839093e+02,  8.07413996e+01,  1.43766496e+02,  8.85321309e+01,\n",
       "          7.46833531e+01,  7.48028991e+01,  9.82242256e+01,  9.71026243e+01,\n",
       "          1.34270572e+02,  7.03446398e+01,  7.08310439e+01,  7.75447774e+01,\n",
       "          6.66707908e+01,  8.80120656e+01,  6.77910817e+01,  8.98327151e+01,\n",
       "          3.66525573e+01,  7.64628434e+01,  6.54290236e+01,  2.72036068e+01,\n",
       "          2.02650646e+01,  9.07493186e+01,  5.98023868e+01,  3.83409678e+01,\n",
       "          1.22069516e+02,  1.31467111e+02,  1.20736105e+02,  1.07073351e+02,\n",
       "          1.46606255e+02,  1.00815546e+02,  1.57868136e+02,  1.69056323e+02,\n",
       "          2.91088702e+02,  2.69217229e+02,  3.38533332e+02,  4.22921850e+02,\n",
       "          2.79703978e+02,  4.09321194e+02,  3.87759114e+02,  5.19917633e+02,\n",
       "          4.68231881e+02,  4.55148853e+02,  4.81992976e+02,  4.62211969e+02,\n",
       "          2.91362640e+02,  2.61090586e+02,  2.36236491e+02,  2.61619157e+02,\n",
       "          2.56410267e+02,  2.82913014e+02,  2.23888252e+02,  1.64335113e+02,\n",
       "          2.43377926e+02,  3.02310103e+02,  1.60741129e+02,  1.81553390e+02,\n",
       "          3.46233513e+02, -1.12601451e+02, -2.19580198e+02,  4.25080197e+02,\n",
       "          4.21766577e+02, -2.48565052e+01,  9.78584680e+01,  2.49129979e+02,\n",
       "          1.06255905e+01,  2.56874471e+02,  2.13264403e+02,  9.80892587e+01,\n",
       "          1.88897937e+02,  1.46849737e+02,  2.59446315e+02,  1.37816639e+02,\n",
       "          1.04346078e+02,  1.04710427e+02,  6.53300255e+02,  5.87900978e+02,\n",
       "          6.49352817e+02,  6.74683224e+02,  9.23082348e+02,  7.03886298e+02,\n",
       "          1.34075914e+03,  1.83081148e+03,  3.17041776e+03,  3.76983034e+03,\n",
       "          4.54756936e+03,  4.29636941e+03,  4.93027157e+03,  5.74639615e+03,\n",
       "          5.05239942e+03,  5.42305760e+03,  4.42677107e+03,  4.85519103e+03,\n",
       "          2.86708423e+03,  2.73206331e+03,  1.71999688e+03,  1.88041531e+03,\n",
       "          2.01915071e+03,  1.10568875e+03,  6.90584919e+02,  7.00774045e+02,\n",
       "          7.93147578e+02,  5.35889862e+02,  5.94299800e+02,  4.36444937e+02,\n",
       "          7.09008233e+02,  6.25742911e+02,  4.53371698e+02,  4.72463106e+02,\n",
       "          1.20717850e+03,  7.73857572e+02,  8.76680943e+02,  6.05224469e+02,\n",
       "          1.14096355e+03,  9.20351757e+02,  9.50020462e+02,  1.33846373e+03,\n",
       "          1.94433676e+03,  3.38278290e+03,  3.31123343e+03,  2.48646862e+03,\n",
       "          2.01745883e+03,  3.23784795e+03,  2.05613706e+03,  8.59993064e+02,\n",
       "         -1.52249180e+02, -2.01452149e+02,  7.17457378e+03,  4.49715411e+03,\n",
       "          4.61179951e+03,  4.62601839e+03,  4.73493392e+03,  6.26447739e+03,\n",
       "          4.43283152e+03,  4.17464480e+03,  3.47820246e+03,  2.42150957e+03,\n",
       "          1.87796484e+03,  1.79319707e+03,  1.13508344e+03,  2.09788582e+03,\n",
       "          4.06954978e+02,  8.53507816e+02,  6.21595646e+02,  7.58804263e+02,\n",
       "          6.24252597e+02,  5.15934898e+02,  6.56386472e+02,  5.31629412e+02,\n",
       "          4.58528180e+02,  5.00664468e+02,  2.76827014e+02,  3.00212627e+00,\n",
       "          6.25632932e+02,  3.35506620e+02,  9.18298248e+01,  5.55983906e+01,\n",
       "          4.70990032e+02,  1.91305878e+02,  1.57176532e+02,  2.63102206e+02,\n",
       "          1.00735474e+02,  1.58561305e+02,  1.93580749e+02,  1.79503859e+02,\n",
       "          1.13032020e+02,  1.83921702e+02,  1.05786274e+02,  1.19202745e+02,\n",
       "          1.05753406e+02,  1.17118656e+02,  9.65455362e+01,  1.30730695e+02,\n",
       "          7.09617642e+01,  8.35886667e+01,  1.25195143e+02,  8.03534132e+01,\n",
       "          4.03799733e+01]),\n",
       "  'mse': 187221.4311460763,\n",
       "  'mape': 36.76941401720996},\n",
       " 'ensemble': {'weights': {'arima': 0.4, 'knn': 0.1, 'vgg': 0.5},\n",
       "  'mse': 120606.23230979955,\n",
       "  'mape': 22.146850727051476,\n",
       "  'test_pred': array([ 114.37714865,   26.55977481,   76.63925101,   79.86983355,\n",
       "           65.94475602,   76.00955828,   67.70554469,  103.61231601,\n",
       "           56.86505609,   80.42954852,   43.63392364,   55.10488583,\n",
       "           90.93018351,   47.75007069,   35.84541514,   61.68960212,\n",
       "           58.75471549,   87.30448514,   95.06841441,   73.57629948,\n",
       "           97.91170269,  117.23335739,  130.7440668 ,  159.16948554,\n",
       "          143.43192914,  197.45864674,  217.1097945 ,  234.27304822,\n",
       "          308.43262645,  409.53968109,  397.76094735,  368.02966283,\n",
       "          362.54460727,  394.40453212,  294.34742934,  312.61615806,\n",
       "          301.24318676,  262.18300657,  227.95579757,  169.27733772,\n",
       "          161.03338712,  153.01507988,  126.33179701,  165.75435155,\n",
       "          133.14989254,  165.16089222,  166.172902  ,  112.43352338,\n",
       "          140.38022323,  104.40831033,   92.62155359,   91.38410089,\n",
       "          106.09964285,  109.28516949,  137.7029721 ,   96.78591002,\n",
       "           86.8159845 ,   82.95526541,   71.11043847,   86.46548647,\n",
       "           76.9885443 ,   94.09743007,   59.62589956,   75.65624446,\n",
       "           68.7837696 ,   45.62416854,   37.00470551,   76.44975431,\n",
       "           73.58279995,   58.87748108,  119.04562012,  146.8962342 ,\n",
       "          135.92382437,  124.59764857,  145.46126406,  112.3484778 ,\n",
       "          147.1456061 ,  163.93406635,  280.96215918,  306.6785355 ,\n",
       "          368.11686317,  425.44363056,  322.44828863,  389.22557606,\n",
       "          373.95554389,  477.8693498 ,  490.94010357,  441.55398243,\n",
       "          454.79413816,  437.11492964,  325.88027981,  266.8093553 ,\n",
       "          230.46540901,  228.83704502,  230.62312621,  211.62462875,\n",
       "          172.79737023,  127.83972258,  147.21380319,  122.95073973,\n",
       "          113.3132564 ,   83.9207133 ,  130.88824288,   84.6919584 ,\n",
       "           97.40225738,  116.99685533,   94.30688264,  106.7838752 ,\n",
       "          117.58601451,  144.54992154,  122.03537483,  178.93336914,\n",
       "          159.71370337,  169.74858368,  145.39848082,  173.1531985 ,\n",
       "          219.97749207,  171.59178448,  115.63470762,  102.0794627 ,\n",
       "          504.70275184,  637.85279461,  744.29578604,  733.89334757,\n",
       "          908.3300301 ,  729.50008556, 1187.55039984, 1740.00640527,\n",
       "         3083.09908828, 4035.53892672, 4858.73286103, 4498.57941998,\n",
       "         4668.74361711, 5127.49459921, 4687.60273938, 4989.56993269,\n",
       "         4245.05373363, 4337.85778431, 3004.88429266, 2629.46036916,\n",
       "         1924.65183984, 1718.56950852, 1653.37435835, 1169.04400694,\n",
       "          903.28860504,  821.31988386,  781.36783698,  638.62101822,\n",
       "          580.26017955,  500.05429462,  578.22950372,  622.83997816,\n",
       "          517.46809258,  524.90920383, 1014.65514864,  880.30745479,\n",
       "          933.51439931,  665.01488794,  958.76027268,  898.14572099,\n",
       "          912.98753167, 1221.23979819, 1841.88331481, 3238.99900299,\n",
       "         3610.27685361, 2788.97878726, 2077.02214281, 2512.6613784 ,\n",
       "         1831.36498821, 1115.59943754,  566.57807358,  413.44279186,\n",
       "         5147.4285333 , 5150.3738624 , 5276.05074793, 4931.76736694,\n",
       "         4567.62097257, 5277.35577892, 4191.95164563, 3886.77951616,\n",
       "         3286.70079712, 2469.21519718, 1991.75892051, 1699.52390888,\n",
       "         1212.21004061, 1327.26947318,  930.96544964,  840.88380544,\n",
       "          693.23508035,  652.39257209,  549.64327429,  621.45906387,\n",
       "          429.68085127,  410.31099255,  427.21375462,  386.69978698,\n",
       "          299.29731573,  291.78941873,  230.86136958,  337.14660364,\n",
       "          212.58154835,  240.74311357,  226.18097058,  258.59999494,\n",
       "          233.33814777,  187.25893467,  173.29652145,  144.60837462,\n",
       "          144.94678119,  150.21858875,  126.32082631,  158.85440546,\n",
       "          116.97299995,  131.52889594,  127.39500533,  133.49044496,\n",
       "          112.90086965,  125.56594523,   98.69362199,   82.17894601,\n",
       "          110.82334432,   86.67421086,   60.92674522])}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Setor 9 — Sistema Híbrido (Residual Stacking + Ensemble)\n",
    "# Combina previsões do ARIMA, KNN e VGG para melhorar o desempenho final.\n",
    "# Inclui correções automáticas de alinhamento entre séries com janelas diferentes.\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# === Função de alinhamento entre modelos base ===\n",
    "def align_for_ensemble(ar_val, ar_test, knn_best, vgg_best):\n",
    "    cand = {\"arima\": {\"val\": ar_val, \"test\": ar_test}}\n",
    "    cand[\"knn\"] = {\"val\": knn_best[\"preds\"][\"val\"], \"test\": knn_best[\"preds\"][\"test\"]}\n",
    "    if not vgg_best.get(\"disabled\", False):\n",
    "        cand[\"vgg\"] = {\"val\": vgg_best[\"preds\"][\"val\"], \"test\": vgg_best[\"preds\"][\"test\"]}\n",
    "    return cand\n",
    "\n",
    "\n",
    "# === Função do modelo híbrido Residual Stacking ===\n",
    "def residual_stacking(y_val, y_test, base_val, base_test, extra_dict):\n",
    "    \"\"\"\n",
    "    Modelo híbrido por empilhamento residual (Residual Stacking).\n",
    "    Treina um regressor para aprender os resíduos do modelo base (ARIMA),\n",
    "    usando previsões adicionais (KNN, VGG) como features.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Criação dos DataFrames ---\n",
    "    Xv = pd.DataFrame({k: v for k, v in extra_dict.items()})\n",
    "    Xt = pd.DataFrame({k: v for k, v in extra_dict.items()})\n",
    "\n",
    "    # --- Alinhamento automático de tamanhos ---\n",
    "    min_len_v = min(len(y_val), *[len(v) for v in extra_dict.values()], len(base_val))\n",
    "    y_val = y_val.iloc[-min_len_v:]\n",
    "    base_val = base_val[-min_len_v:]\n",
    "    Xv = Xv.iloc[-min_len_v:]\n",
    "\n",
    "    min_len_t = min(len(y_test), *[len(v) for v in extra_dict.values()], len(base_test))\n",
    "    y_test = y_test.iloc[-min_len_t:]\n",
    "    base_test = base_test[-min_len_t:]\n",
    "    Xt = Xt.iloc[-min_len_t:]\n",
    "\n",
    "    # --- Treinamento do modelo de resíduos ---\n",
    "    res_val = y_val.values - base_val\n",
    "    gbr = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "    gbr.fit(Xv, res_val)\n",
    "\n",
    "    # --- Predição dos resíduos e reconstrução final ---\n",
    "    res_te = gbr.predict(Xt)\n",
    "    out = base_test[-len(res_te):] + res_te\n",
    "    return out\n",
    "\n",
    "\n",
    "# === Função de busca de pesos para Ensemble ===\n",
    "def ensemble_search(y_val, y_test, cand):\n",
    "    names = list(cand.keys())\n",
    "    step = CFG[\"ensemble_weight_step\"]\n",
    "    best = {\"score\": math.inf}\n",
    "\n",
    "    if len(names) == 2:\n",
    "        wgrid = np.arange(0, 1 + step, step)\n",
    "        for w in wgrid:\n",
    "            pv = w * cand[names[0]][\"val\"] + (1 - w) * cand[names[1]][\"val\"]\n",
    "            sc = mse(y_val.values, pv)\n",
    "            if sc < best[\"score\"]:\n",
    "                pt = w * cand[names[0]][\"test\"] + (1 - w) * cand[names[1]][\"test\"]\n",
    "                best = {\"score\": sc,\n",
    "                        \"weights\": {names[0]: float(w), names[1]: float(1 - w)},\n",
    "                        \"test_pred\": pt}\n",
    "\n",
    "    elif len(names) == 3:\n",
    "        wgrid = np.arange(0, 1 + step, step)\n",
    "        for w1 in wgrid:\n",
    "            for w2 in wgrid:\n",
    "                w3 = 1 - w1 - w2\n",
    "                if w3 < -1e-9:\n",
    "                    continue\n",
    "                pv = (w1 * cand[names[0]][\"val\"] +\n",
    "                      w2 * cand[names[1]][\"val\"] +\n",
    "                      w3 * cand[names[2]][\"val\"])\n",
    "                sc = mse(y_val.values, pv)\n",
    "                if sc < best[\"score\"]:\n",
    "                    pt = (w1 * cand[names[0]][\"test\"] +\n",
    "                          w2 * cand[names[1]][\"test\"] +\n",
    "                          w3 * cand[names[2]][\"test\"])\n",
    "                    best = {\"score\": sc,\n",
    "                            \"weights\": {names[0]: float(w1),\n",
    "                                        names[1]: float(w2),\n",
    "                                        names[2]: float(w3)},\n",
    "                            \"test_pred\": pt}\n",
    "    else:\n",
    "        raise ValueError(\"Ensemble implementado apenas para 2 ou 3 modelos.\")\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "# === Execução do sistema híbrido ===\n",
    "cand = align_for_ensemble(ar_va_p, ar_te_p, knn_best, vgg_best if not vgg_best.get(\"disabled\", False) else {})\n",
    "hybrid = {}\n",
    "\n",
    "# --- Residual Stacking ---\n",
    "if CFG[\"hybrid_residual\"]:\n",
    "    extra = {\"knn\": cand[\"knn\"][\"val\"]}\n",
    "    if \"vgg\" in cand:\n",
    "        extra[\"vgg\"] = cand[\"vgg\"][\"val\"]\n",
    "\n",
    "    rs_test = residual_stacking(pd.Series(yva_p, index=y_val.index),\n",
    "                                pd.Series(yte_p, index=y_test.index),\n",
    "                                cand[\"arima\"][\"val\"], cand[\"arima\"][\"test\"], extra)\n",
    "\n",
    "    # alinhamento final para métricas\n",
    "    min_len_eval = min(len(yte_p), len(rs_test))\n",
    "    yte_aligned = yte_p[-min_len_eval:]\n",
    "    rs_aligned = rs_test[-min_len_eval:]\n",
    "\n",
    "    hybrid[\"residual\"] = {\n",
    "        \"test_pred\": rs_aligned,\n",
    "        \"mse\": mse(yte_aligned, rs_aligned),\n",
    "        \"mape\": mape(yte_aligned, rs_aligned)\n",
    "    }\n",
    "\n",
    "    plot_fit(y_test.index[-min_len_eval:], yte_aligned, rs_aligned,\n",
    "             \"Híbrido (Residual Stacking) - Teste\", \"hybrid_residual_test\")\n",
    "\n",
    "\n",
    "# --- Ensemble de modelos ---\n",
    "if CFG[\"hybrid_ensemble\"]:\n",
    "    ens = ensemble_search(pd.Series(yva_p, index=y_val.index),\n",
    "                          pd.Series(yte_p, index=y_test.index), cand)\n",
    "\n",
    "    min_len_eval = min(len(yte_p), len(ens[\"test_pred\"]))\n",
    "    yte_aligned = yte_p[-min_len_eval:]\n",
    "    ens_aligned = ens[\"test_pred\"][-min_len_eval:]\n",
    "\n",
    "    hybrid[\"ensemble\"] = {\n",
    "        \"weights\": ens[\"weights\"],\n",
    "        \"mse\": mse(yte_aligned, ens_aligned),\n",
    "        \"mape\": mape(yte_aligned, ens_aligned),\n",
    "        \"test_pred\": ens_aligned\n",
    "    }\n",
    "\n",
    "    plot_fit(y_test.index[-min_len_eval:], yte_aligned, ens_aligned,\n",
    "             \"Híbrido (Ensemble) - Teste\", \"hybrid_ensemble_test\")\n",
    "\n",
    "hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae384a6261f6f572",
   "metadata": {},
   "source": [
    "10) Relatório consolidado + apresentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dccd97738cff9f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T00:40:53.806952Z",
     "start_time": "2025-10-07T00:40:53.722433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_82aef\">\n",
       "  <caption>Resumo comparativo de modelos</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_82aef_level0_col0\" class=\"col_heading level0 col0\" >Modelo</th>\n",
       "      <th id=\"T_82aef_level0_col1\" class=\"col_heading level0 col1\" >MSE_train</th>\n",
       "      <th id=\"T_82aef_level0_col2\" class=\"col_heading level0 col2\" >MAPE_train</th>\n",
       "      <th id=\"T_82aef_level0_col3\" class=\"col_heading level0 col3\" >MSE_val</th>\n",
       "      <th id=\"T_82aef_level0_col4\" class=\"col_heading level0 col4\" >MAPE_val</th>\n",
       "      <th id=\"T_82aef_level0_col5\" class=\"col_heading level0 col5\" >MSE_test</th>\n",
       "      <th id=\"T_82aef_level0_col6\" class=\"col_heading level0 col6\" >MAPE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_82aef_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_82aef_row0_col0\" class=\"data row0 col0\" >-</td>\n",
       "      <td id=\"T_82aef_row0_col1\" class=\"data row0 col1\" >47957.2961</td>\n",
       "      <td id=\"T_82aef_row0_col2\" class=\"data row0 col2\" >63.9104</td>\n",
       "      <td id=\"T_82aef_row0_col3\" class=\"data row0 col3\" >11057.8358</td>\n",
       "      <td id=\"T_82aef_row0_col4\" class=\"data row0 col4\" >44.8365</td>\n",
       "      <td id=\"T_82aef_row0_col5\" class=\"data row0 col5\" >175078.4527</td>\n",
       "      <td id=\"T_82aef_row0_col6\" class=\"data row0 col6\" >27.5904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82aef_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_82aef_row1_col0\" class=\"data row1 col0\" >-</td>\n",
       "      <td id=\"T_82aef_row1_col1\" class=\"data row1 col1\" >0.0000</td>\n",
       "      <td id=\"T_82aef_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_82aef_row1_col3\" class=\"data row1 col3\" >45881.2723</td>\n",
       "      <td id=\"T_82aef_row1_col4\" class=\"data row1 col4\" >36.4702</td>\n",
       "      <td id=\"T_82aef_row1_col5\" class=\"data row1 col5\" >584605.2600</td>\n",
       "      <td id=\"T_82aef_row1_col6\" class=\"data row1 col6\" >33.3393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82aef_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_82aef_row2_col0\" class=\"data row2 col0\" >-</td>\n",
       "      <td id=\"T_82aef_row2_col1\" class=\"data row2 col1\" >45192.6680</td>\n",
       "      <td id=\"T_82aef_row2_col2\" class=\"data row2 col2\" >31.2954</td>\n",
       "      <td id=\"T_82aef_row2_col3\" class=\"data row2 col3\" >10469.2900</td>\n",
       "      <td id=\"T_82aef_row2_col4\" class=\"data row2 col4\" >28.8701</td>\n",
       "      <td id=\"T_82aef_row2_col5\" class=\"data row2 col5\" >142786.6406</td>\n",
       "      <td id=\"T_82aef_row2_col6\" class=\"data row2 col6\" >25.5326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82aef_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_82aef_row3_col0\" class=\"data row3 col0\" >-</td>\n",
       "      <td id=\"T_82aef_row3_col1\" class=\"data row3 col1\" >-</td>\n",
       "      <td id=\"T_82aef_row3_col2\" class=\"data row3 col2\" >-</td>\n",
       "      <td id=\"T_82aef_row3_col3\" class=\"data row3 col3\" >-</td>\n",
       "      <td id=\"T_82aef_row3_col4\" class=\"data row3 col4\" >-</td>\n",
       "      <td id=\"T_82aef_row3_col5\" class=\"data row3 col5\" >187221.4311</td>\n",
       "      <td id=\"T_82aef_row3_col6\" class=\"data row3 col6\" >36.7694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82aef_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_82aef_row4_col0\" class=\"data row4 col0\" >-</td>\n",
       "      <td id=\"T_82aef_row4_col1\" class=\"data row4 col1\" >-</td>\n",
       "      <td id=\"T_82aef_row4_col2\" class=\"data row4 col2\" >-</td>\n",
       "      <td id=\"T_82aef_row4_col3\" class=\"data row4 col3\" >-</td>\n",
       "      <td id=\"T_82aef_row4_col4\" class=\"data row4 col4\" >-</td>\n",
       "      <td id=\"T_82aef_row4_col5\" class=\"data row4 col5\" >120606.2323</td>\n",
       "      <td id=\"T_82aef_row4_col6\" class=\"data row4 col6\" >22.1469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17dfd644440>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relatórios gerados em: c:\\Users\\joncu\\OneDrive\\Documentos\\series_temporais_projeto\\out\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Setor 10 — Relatório de Métricas e Exportação (CSV + Markdown)\n",
    "\n",
    "rows = [\n",
    "    (\"ARIMA\",\n",
    "     ar_metrics[\"train\"][\"mse\"], ar_metrics[\"train\"][\"mape\"],\n",
    "     ar_metrics[\"val\"][\"mse\"], ar_metrics[\"val\"][\"mape\"],\n",
    "     ar_metrics[\"test\"][\"mse\"], ar_metrics[\"test\"][\"mape\"]),\n",
    "\n",
    "    (\"KNN\",\n",
    "     mse(knn_best[\"truth\"][\"train\"], knn_best[\"preds\"][\"train\"]),\n",
    "     mape(knn_best[\"truth\"][\"train\"], knn_best[\"preds\"][\"train\"]),\n",
    "     mse(knn_best[\"truth\"][\"val\"], knn_best[\"preds\"][\"val\"]),\n",
    "     mape(knn_best[\"truth\"][\"val\"], knn_best[\"preds\"][\"val\"]),\n",
    "     mse(knn_best[\"truth\"][\"test\"], knn_best[\"preds\"][\"test\"]),\n",
    "     mape(knn_best[\"truth\"][\"test\"], knn_best[\"preds\"][\"test\"])),\n",
    "]\n",
    "\n",
    "# --- Adiciona VGG, se ativo ---\n",
    "if not vgg_best.get(\"disabled\", False):\n",
    "    rows.append((\n",
    "        f\"VGG1D(w={vgg_best['window']}, f={vgg_best['filters']}, d={vgg_best['dropout']})\",\n",
    "        mse(vgg_best[\"truth\"][\"train\"], vgg_best[\"preds\"][\"train\"]),\n",
    "        mape(vgg_best[\"truth\"][\"train\"], vgg_best[\"preds\"][\"train\"]),\n",
    "        mse(vgg_best[\"truth\"][\"val\"], vgg_best[\"preds\"][\"val\"]),\n",
    "        mape(vgg_best[\"truth\"][\"val\"], vgg_best[\"preds\"][\"val\"]),\n",
    "        mse(vgg_best[\"truth\"][\"test\"], vgg_best[\"preds\"][\"test\"]),\n",
    "        mape(vgg_best[\"truth\"][\"test\"], vgg_best[\"preds\"][\"test\"]),\n",
    "    ))\n",
    "\n",
    "# --- Adiciona híbridos (Residual e Ensemble, se existirem) ---\n",
    "for k, v in hybrid.items():\n",
    "    rows.append((\n",
    "        f\"HÍBRIDO-{k.upper()}\",\n",
    "        None, None, None, None,  # híbridos só avaliam no teste\n",
    "        v.get(\"mse\", np.nan),\n",
    "        v.get(\"mape\", np.nan)\n",
    "    ))\n",
    "\n",
    "# --- Monta DataFrame final ---\n",
    "report = pd.DataFrame(rows, columns=[\n",
    "    \"Modelo\", \"MSE_train\", \"MAPE_train\",\n",
    "    \"MSE_val\", \"MAPE_val\", \"MSE_test\", \"MAPE_test\"\n",
    "])\n",
    "\n",
    "# exibe em notebook\n",
    "display(\n",
    "    report.style.format(\n",
    "        lambda v: f\"{v:.4f}\" if isinstance(v, (int, float, np.floating)) and pd.notnull(v) else \"-\"\n",
    "    ).set_caption(\"Resumo comparativo de modelos\")\n",
    ")\n",
    "\n",
    "# --- Salva CSV ---\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "report.to_csv(os.path.join(OUT_DIR, \"metrics_summary.csv\"), index=False)\n",
    "\n",
    "# --- Gera relatório Markdown ---\n",
    "md = [\n",
    "    \"# Projeto – Análise de Séries Temporais e Regressão\",\n",
    "    \"## Série utilizada\",\n",
    "    f\"- Arquivo: `{os.path.basename(DATA_PATH)}`\",\n",
    "    f\"- Coluna temporal detectada: `{detected_date_col}`\",\n",
    "    f\"- Coluna alvo detectada: `{detected_target_col}`\",\n",
    "    \"## Metodologia\",\n",
    "    \"- Split temporal: **50% / 25% / 25%** (ordem preservada)\",\n",
    "    \"- **ARIMA/SARIMA (Box–Jenkins)** – Seleção via AIC e teste de Ljung–Box\",\n",
    "    \"- **KNN** – Lags + estatísticas móveis; parâmetros ajustados por validação\",\n",
    "    \"- **VGG-1D** – CNN 1D com janelas deslizantes; early stopping via validação\",\n",
    "    \"- **Híbridos** – Residual Stacking e Ensemble ponderado (pesos via validação)\",\n",
    "    \"## Comparação (MSE / MAPE)\",\n",
    "    report.to_markdown(index=False)\n",
    "]\n",
    "\n",
    "with open(os.path.join(OUT_DIR, \"presentation.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\".join(md))\n",
    "\n",
    "print(\"✅ Relatórios gerados em:\", os.path.abspath(OUT_DIR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
